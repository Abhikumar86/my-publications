
# Plant Ecology in Indian Siwaliks

## Abstract

Conservation science and practice commonly draw on the theories and methods of social psychology to explain human cognition, emotion, and behaviour germane to biodiversity conservation. We created a systematic map of the cross-disciplinary conservation science literature, which draws on social psychology concepts and methods in their application broadly described as conservation psychology. Established protocols were used to systematically collect and collate peer-reviewed research published in an explicit selection of multidisciplinary conservation journals. We sought to catalogue the literature, elucidate trends and gaps, and critically reflect on the state of conservation psychology and its research practices that aim to influence conservation outcomes. The volume of publications per year and per decade increased from 1974 to 2016. Although a diversity of research designs and methods was applied, studies disproportionately focused on specific concepts (attitudes and beliefs), locations (North America and Europe), and contexts (terrestrial, rural). Studies also tended to be descriptive, quantitative, and a theoretical in nature. Our findings demonstrate that although conservation psychology has generally become more visible and prominent, it has done so within a limited space and suggest that disciplinary research principles and reporting standards must be more universally adopted by traditional and multidisciplinary conservation journals to raise the floor of empirical research.

## Introduction

The rate of anthropogenic biodiversity loss far exceeds the background rate of species extinctions. Global targets for biodiversity acknowledge this, nevertheless progress towards targets has been poor. There is now a reasonable understanding of what human pressures threaten the survival of species. However, information on where these threats are impacting species is needed to coordinate conservation actions and threat abatement efforts. Herein, threats are defined as human-driven pressures specifically where they co-occur with, and threaten the survival of, native wild species. There is a large number of studies that map either distributions of threatened species or human-driven pressures alone. This makes it difficult to identify research that has investigated the spatial distribution of the threats themselves. Additionally, the high variability in approaches taken in these studies promotes a high risk of duplication and diversity among the findings. This variation, and the lack of studies directly mapping threats, limits the utility of threat mapping studies for conservation planning and informing policy. Therefore, a systematic consolidation of the literature is necessary to identify where knowledge is lacking, and where sufficient evidence exists for synthesis of the collective findings.
Understanding ecological structure and functions is vital for ensuring the sustainability of any ecosystem. 
Objective of the review
Ecological studies Concern/Problem
Ecology enriches our world and is crucial for human wellbeing and prosperity. It provides new knowledge of the interdependence between people and nature that is vital for food production, maintaining clean air and water, and sustaining biodiversity in a changing climate.
There is a need to know the quantity and quality of research that has been conducted on a specific question.
A descriptive overview is required of the evidence base for a given topic

Systematic mapping provides a snapshot of the current state of knowledge, identifying areas needing more research attention and those ready for full synthesis.

## Objectives

This review aims to describe the focus of plant ecological studies by analysing the current evidence of existing studies. Further, we will identify the clusters and gaps in the current knowledge, which will guide the future investigations.

* **Primary question:** What evidence exists for research focusing on plant ecology in Indian Siwaliks?
	- **Population:** The evidence base of studies focusing plant ecology in Indian Siwaliks. The taxonomic scope of this review is any plant species in the Siwaliks of north-west India. The siwalik region has been defined as the foothills of the Himalayas and spatially as defined by the Geological Survey of India (https://bhukosh.gsi.gov.in/Bhukosh/MapViewer.aspx).
	- **Outcome:** The distribution of studies focusing plant ecology will be the outcome to be analysed. The studies to be included must have addressed any aspect of plant ecology. By Plant Ecology, we mean studies addressing distribution of plants, and interactions of plants with environment or other species. Thus, the studies must have plants as one of the components under study. However, this study will not focus on agroecological aspects, therefore studies focusing on agricultural systems will be beyond the scope of this review.

* **Secondary questions**
	- What is the geographical distribution of the evidence?
	- What is the temporal distribution of the evidence?
	- Which domains of ecology are frequently studied?
	- What taxonomic groups of plants have been studied?	
	- What are the knowledge gaps that need to be addressed?

## Methodology

### Literature Database

Scopus (https://scopus.com/) and Web of Science Core Collection (https://webofknowledge.com/) are the most reliable databases for retrieval of high-quality peer-reviewed scientific literature in the fields of Science and Technology. The Web of Science Core Collection TM consists of Science Citation Index Expanded (SCIE), Social Sciences Citation Index (SSCI), Arts & Humanities Citation Index (AHCI), Conference Proceedings Citation Index (CPCI), Book Citation Index (BCI), Emerging Sources Citation Index (ESCI), and Current Chemical Reactions and Index Chemicus (https://clarivate.com/webofsciencegroup/solutions/web-of-science-core-collection/). For this database (“Web of Science Core Collection”), our institution provided us access to “Science Citation Index Expanded” (SCI-EXPANDED), “Social Sciences Citation Index” (SSCI) and “Arts & Humanities Citation Index” (A&HCI) for the timespan 1989-present. Both databases allow to export bibliographic meta-data offer great accuracy and reproducibility of literature search. However, access to these databases required a subscription through payment of large money. Although both databases emerged in 2004, Scopus offers relatively larger coverage of scientific literature whereas Web of Science provides offers coverage from early 1900.  
On the other hand, Google Scholar (https://scholar.google.com/) is freely available and has most comprehensive coverage as it offers retrieval of most obscure information. Although it also provides access to full text articles, it is not a bibliographic database. Its content is dynamic and has compromised accuracy. Further, it lacks several functionalities in literature search like subject filtering and tagging. Considering these limitations, we limited our literature search to two bibliographic databases of peer-reviewed literature (Web of Science Core Collection and Scopus).

### Search strings

We identified the terms that are frequently applied to the region using a preliminary literature search and discussion with review team members. Using combination of these terms, we developed a common search string for 
Web of Science and Scopus. 

> (Siwalik OR Siwalik OR Shivalik OR Sivalik) OR (himalaya* AND (foothill* OR outer OR sub)) OR (hill* AND (jammu OR kangra Or morni or mohand)) OR (range* AND (dudhwa OR dundwa))  


### Literature Search

* Scopus (https://scopus.com/): We have queried the above defined search string to the “Article title, Abstract, Keywords” in “Documents” using the default options for “Limit” (Date range (inclusive): Published from “All years” to “Present”; Document type: “ALL”). This query returned a total of 4,102 document results on 03 April 2021. Then, we have filtered the results by limiting subject to “Agricultural and Biological Sciences” and “Environmental Science” subject areas, which yielded a total of 1,875 documents. All these documents were selected by choosing “Select All” option and then exported all information by selecting “Citation information”, “Bibliographical information”, “Abstract & keywords”, “Funding details” and “Other information” in the BibTex format. 

* Web of Science Core Collection (https://webofknowledge.com/): The same keyword combination was queried in the “Topic” field of Web of Science by selecting the database “Web of Science Core Collection”. Default settings (Web of Science Core Collection: Citation Indexes - Science Citation Index Expanded (SCI-EXPANDED) --1989-present, Social Sciences Citation Index (SSCI) --1989-present, and Arts & Humanities Citation Index (A&HCI) --1989-present; Auto-suggest publication names: On; and Default Number of Search Fields to Display: 1 field (Topic)) were used under the more settings option. This yielded us 2,978 results on 03 April 2021. Then the results were refined by selecting following Web of Science categories: ENVIRONMENTAL SCIENCES, PLANT SCIENCES, PALEONTOLOGY, ECOLOGY, BIOLOGY, REMOTE SENSING, SOIL SCIENCE, BIODIVERSITY CONSERVATION, FORESTRY, EVOLUTIONARY BIOLOGY, and ENVIRONMENTAL STUDIES. This yielded a total of 1,013 results. Then the “Show” option was changed from “10 per page” (Default) to “50 per page”. Next, all entries on a page were first selected using the “Select Page” option and then added to “Marked List” using the “Add to Marked List” button. This was repeated for all the 21 pages and thus all the 1,103 entries were added to the “Marked List”. Since Web of Science allows export of 500 records at time, we have first selected the first 500 records by defining the record range “Records: 1 to 500” under the “Step 1: Select records.” option. Then we have selected all the fields using the “Select All” option under “Step 2: Select content. Select from the fields below:” option. Next, we have exported the records in BibTex format using the “Export” option under the “Step 3: Select destination.” And then choosing the “BibTex” option under the “Other File Formats”. The same process was repeated for records 501 to 1,000 and 1,001 to 1,013.

###	Article screening


```r
## set global options for markdown
knitr::opts_chunk$set(comment = "#>", collapse = TRUE, fig.align = 'center', 
			    fig.width = 7, fig.height = 5, out.width = '80%', 
			    message=FALSE, warning=FALSE)
## load the required packages
library(dplyr) # general data manipulation and operations
library(ggplot2) # data visualisation
library(knitr) # for document tables
library(raster) # for raster data operations
library(revtools) # review tools functions for bibliography and article screening
library(sf) # spatial data operations
library(tmap) # spatial data visualisation and mapping
```


#### De-duplication

Database may have erroneous duplications or due to automated information extraction systems. Thus, the documents can be largely duplicated within and across literature databases. These duplicates might waste the energy and time of the reviewers apart from erroneous results of reviews. Therefore, removal of duplicates is necessary. 
Several procedures and software are available for automated de-duplication of literature. Here, we have first de-duplicated the documents based on doi (digital object identifier) of each articles. Then, we have de-duplicated by matching title of each article. However, the upper- or lower case and punctuations can interfere with title matching. Therefore, we converted titles to lower case and removed punctuations before matching. Thus, after de-duplication we are left with 2,171 (unique doi = 2366, unique doi + unique title = 2171) articles out of total 2,888 articles. After this, we have performed manual screening of duplicates, if remained any.


```r
## read all the bibliography
data_all <- read_bibliography(c("./data/siwalik-ecology/scopus.bib", 
					  "./data/siwalik-ecology/wos1.bib", 
					  "./data/siwalik-ecology/wos2.bib", 
					  "./data/siwalik-ecology/wos3.bib"))

## identify and remove duplicates by doi
match.doi <- find_duplicates(data = data_all) # match by doi
unique_doi <- extract_unique_references(x = data_all, matches = match.doi)

## identify and remove duplicates by title
# exact title matching
match.title <- find_duplicates(data = unique_doi, match_variable = "title",
					 to_lower = TRUE, remove_punctuation = TRUE)
unique_title <- extract_unique_references(x = unique_doi, matches = match.title)

## write and save unique references
#write_bibliography(x = unique_title, filename = "./data/siwalik-ecology/unique_refs.ris", 
			 #format = "ris")
## remove variables from the environment
rm(list = ls()) 
```

#### Title & Abstract screening

After de-duplication of articles, we performed article screening based on their titles. We have hidden every other information during title screening to avoid any potential bias. We assigned three labels to each article
(i) selected, 
(ii) excluded, or 
(iii) unknown. 
We proposed to include those titles which reflected studies related to plant distributions and their interactions with environment. Additionally, we included studies indicated ecosystem processes such as nutrient cycling, carbon sequestration, and biomass production. We also included titles referring to the palaeoecological studies such as fossil distribution and past vegetation evidences. However, we excluded those titles which are reflecting studies related to any group of animals, fungi or other invertebrates. The studies related to agriculture, ethnobotanical uses, phytochemical characterisation, traditional use, cytology, and genetics, which were not relevant to plant ecology were excluded. 


```r
## read the unique articles
unique_refs <- read_bibliography(filename = "./data/siwalik-ecology/unique_refs.ris")
## screen titles of unique articles
sc_titles <- screen_titles(unique_refs)
## write screened titles to local file
#write.csv(sc_titles, "./data/siwalik-ecology/screened_titles.csv")
## remove all variables from the environment
rm(list = ls()) 
```


```r
# summary of title screening
read.csv("./data/siwalik-ecology/screened_titles.csv")$screened_titles %>% table() %>% 
	t() %>% kable(caption = "Summary of title screening")
```



Table: (\#tab:tab1)Summary of title screening

| excluded| selected| unknown|
|--------:|--------:|-------:|
|     1796|      158|     217|

We excluded 1,796 articles based on title screen and remaining 375 articles were selected for abstract screening out of which 158 articles were assigned "selected" and 217 articles were assigned "unknown" during the title screening (Table \@ref(tab:tab1)). Next, we removed the "excluded" articles and screened for abstracts.


```r
## read screened titles and filter the included titles
included_title <- read.csv("./data/siwalik-ecology/screened_titles.csv") %>% 
      filter(screened_titles != "excluded")
## screen abstracts of included titles
sc_abstracts <- screen_abstracts(included_title)
## write screened abstracts
#write.csv(sc_abstracts, "./data/siwalik-ecology/screened_abstracts.csv")
## remove variables from the environment
rm(list = ls()) 
```


```r
## summary of abstract screening
read.csv("./data/siwalik-ecology/screened_abstracts.csv")$screened_abstracts %>% 
      table() %>% t() %>% kable(caption = "Summary of abstract screening")
```



Table: (\#tab:tab2)Summary of abstract screening

| excluded| selected|
|--------:|--------:|
|      264|      111|

After screening abstracts, we excluded 264 articles and left with only 111 articles. Then we filtered these 111 articles and saved the included articles. 


```r
## read screened abstracts and filter the included abstracts
included_abstracts <- read.csv("./data/siwalik-ecology/screened_abstracts.csv") %>% 
      filter(screened_abstracts != "excluded")
## write included abstracts
#write.csv(x = included_abstracts, 
			 #file = "./data/siwalik-ecology/included_abstracts.csv")
```

Then we searched for full text for every article from publisher's website, Google Scholar, Research Gate and institutional repositories. We were not able to retrieve fulltext of following 11 articles.

1. Devi, B., Bhardwaj, D. R., Panwar, P., Pal, S., Gupta, N. K., & Thakur, C. L. (2013). Long term effects of natural and plantation forests on carbon sequestration and soil properties in mid-hill sub-humid condition of Himachal Pradesh, India. *Range Management and Agroforestry, 34*, 19–25.
2. Mehta, S., & Singh, Y. (1994). Spatio-temporal changes in the natural hilly ecosystem: a case study of the Chandigarh Siwalik Hills. *Transactions - Institute of Indian Geographers, 16*, 135–146.
3. Pandey, R. K., Bindroo, B. B., Dhar, A., & Khan, M. A. (2010). Oak regeneration in Sub-Himalayan India. *Indian Silk, 1*, 19–21.
4. Panwar, P., Pal, S., Bhatt, V. K., & Prasad, R. (2014). Land use and canopy positions affect organic carbon pools and fertility of soils in lower Himalayan region, India. *Agrochimica, 58*, 51–62.
5. Pokhriyal, T. C., Chaukiyal, S. P., & Himmat Singh, K. C. (1996). Nitrogen fixation and nodulation behaviour in relation to seasonal changes in six multipurpose tree species. *Indian Forester, 122*, 718–726.
6. Purohit, S., Aggarwal, S. P., & Patel, N. R. (2021). Estimation of forest aboveground biomass using combination of Landsat 8 and Sentinel-1A data with random forest regression algorithm in Himalayan Foothills. *Tropical Ecology, 62*, 288–300. https://doi.org/10.1007/s42965-021-00140-x
7. Rajwar, G. S. (1991). *Advances in Himalayan Ecology*. Today & Tomorrow’s Printers and Publishers, New Delhi.
8. Rajwar, G. S. (1993). *Garhwal Himalaya: Ecology and Environment*. Ashish Publishing House, New Delhi.
9. Ram, N., & Jana, M. M. (1997). Ecological impact of compaction under teak plantation in the foothill of darjeeling himalaya. *Indian Forester, 123*, 623–630.
10. Rout, S., & Gupta, S. (1989). Soil respiration in relation to abiotic factors, forest floor litter, root biomass and litter quality in forest ecosystems of Siwaliks in Northern India. *Acta Oecologica. Oecologia Plantarum, 10*(3), 229–244.
11. Singh, R., Goraya, G. S., Singh, C., Kumar, S., & Kumar, S. (2001). Mortality of Chir pine trees by insect borers in Morni Hills, Haryana - A case study. *Indian Forester, 127*, 1279–1286.

We excluded these 11 articles and screened fulltext of articles.

#### Full text screening
For full text screening, we first selected three variables (`label`, `journal` and `year`) from the included abstracts. Then, we manually screened articles based on the fulltext of every article.


```r
## read the included abstracts and select the label, journal and year columns
included_abstracts <- read.csv("./data/siwalik-ecology/included_abstracts.csv") %>%
	dplyr::select(label, journal, year)
## write included abstracts with selected column
#write.csv(x = included_abstracts, file = "./data/siwalik-ecology/screened_fulltext.csv")
## read the screened fulltext
screened_fulltext <- read.csv("./data/siwalik-ecology/screened_fulltext.csv")
```


```r
## summary of fulltext screening
screened_fulltext$screened_fulltext %>% table() %>% t() %>% 
	kable(caption = "Summary of fulltext screening")
```



Table: (\#tab:tab3)Summary of fulltext screening

| excluded| selected|
|--------:|--------:|
|       71|       40|


Full-text screening resulted in exclusion of 71 articles and we left with 40 articles.


```r
DiagrammeR::grViz("
			digraph G{
			
			graph[ranksep=0.05]
			
			subgraph cluster_searching{
			label=Searching; style=filled; color=mintcream;fontsize=18
			node[label='Scopus\n(n = 1,876)', shape=box, width=2, fillcolor=grey95]searching_A;
			node[label='Web of Science\n(n = 1,013)', shape=box, width=3]searching_B;
			node[label='Total articles\n(n = 2,888)', shape=box, width=3]searching_C;
			searching_A -> searching_C[constraint=false]
			searching_B -> searching_C
			{rank=same;searching_A;searching_C}
			}
			
			subgraph cluster_screening{
			label=Screening; style=filled; color=lightyellow; shape=box;fontsize=18
			node[label='Records after duplicates removed \n (n = 2,171)', shape=box, width=3]screening_1
			node[label='Records after title screening \n (n = 375)', shape=box, width=3]screening_2
			node[label='Records after abstract screening \n (n = 111)',shape=box, width=3]screening_3
			node[label='Articles retrieved at full text \n (n = 100)',shape=box, width=3]screening_4
			node[label='Articles after full text screening \n (n = 40)',shape=box, width=3]screening_5
			
			node[label='Duplicates \n (n = 717)', shape=box, width=2]screening_a
			node[label='Excluded titles \n (n = 1,796)', shape=box, width=2]screening_b
			node[label='Excluded abstracts \n (n = 264)', shape=box, width=2]screening_c
			node[label='Unretrievable full text \n (n = 11)', shape=box, width=2]screening_d
			node[label='Excluded articles \n (n = 71)', shape=box, width=2]screening_e
		
			searching_C -> screening_1 -> screening_2 -> screening_3 -> screening_4 -> screening_5
			screening_1 -> screening_a
			screening_2 -> screening_b
			screening_3 -> screening_c
			screening_4 -> screening_d
			screening_5 -> screening_e
		
			{rank=same;screening_1;screening_a;}
			{rank=same;screening_2;screening_b;}
			{rank=same;screening_3;screening_c;}
			{rank=same;screening_4;screening_d;}
			{rank=same;screening_5;screening_e;}
			}
			
			subgraph cluster_articles{
			label='';style=filled;color=whitesmoke;
			node[label='Studies included in synthesis \n (n = 40)', shape=box, width=3]articles_A
		
			screening_5 -> articles_A[label='Included articles';fontsize=18]
			}
			
			}
			",
			height = 800, width = 750)
```

```{=html}
<div id="htmlwidget-b78097dbeb4e49dc8cb7" style="width:750px;height:800px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-b78097dbeb4e49dc8cb7">{"x":{"diagram":"\n\t\t\tdigraph G{\n\t\t\t\n\t\t\tgraph[ranksep=0.05]\n\t\t\t\n\t\t\tsubgraph cluster_searching{\n\t\t\tlabel=Searching; style=filled; color=mintcream;fontsize=18\n\t\t\tnode[label=\"Scopus\n(n = 1,876)\", shape=box, width=2, fillcolor=grey95]searching_A;\n\t\t\tnode[label=\"Web of Science\n(n = 1,013)\", shape=box, width=3]searching_B;\n\t\t\tnode[label=\"Total articles\n(n = 2,888)\", shape=box, width=3]searching_C;\n\t\t\tsearching_A -> searching_C[constraint=false]\n\t\t\tsearching_B -> searching_C\n\t\t\t{rank=same;searching_A;searching_C}\n\t\t\t}\n\t\t\t\n\t\t\tsubgraph cluster_screening{\n\t\t\tlabel=Screening; style=filled; color=lightyellow; shape=box;fontsize=18\n\t\t\tnode[label=\"Records after duplicates removed \n (n = 2,171)\", shape=box, width=3]screening_1\n\t\t\tnode[label=\"Records after title screening \n (n = 375)\", shape=box, width=3]screening_2\n\t\t\tnode[label=\"Records after abstract screening \n (n = 111)\",shape=box, width=3]screening_3\n\t\t\tnode[label=\"Articles retrieved at full text \n (n = 100)\",shape=box, width=3]screening_4\n\t\t\tnode[label=\"Articles after full text screening \n (n = 40)\",shape=box, width=3]screening_5\n\t\t\t\n\t\t\tnode[label=\"Duplicates \n (n = 717)\", shape=box, width=2]screening_a\n\t\t\tnode[label=\"Excluded titles \n (n = 1,796)\", shape=box, width=2]screening_b\n\t\t\tnode[label=\"Excluded abstracts \n (n = 264)\", shape=box, width=2]screening_c\n\t\t\tnode[label=\"Unretrievable full text \n (n = 11)\", shape=box, width=2]screening_d\n\t\t\tnode[label=\"Excluded articles \n (n = 71)\", shape=box, width=2]screening_e\n\t\t\n\t\t\tsearching_C -> screening_1 -> screening_2 -> screening_3 -> screening_4 -> screening_5\n\t\t\tscreening_1 -> screening_a\n\t\t\tscreening_2 -> screening_b\n\t\t\tscreening_3 -> screening_c\n\t\t\tscreening_4 -> screening_d\n\t\t\tscreening_5 -> screening_e\n\t\t\n\t\t\t{rank=same;screening_1;screening_a;}\n\t\t\t{rank=same;screening_2;screening_b;}\n\t\t\t{rank=same;screening_3;screening_c;}\n\t\t\t{rank=same;screening_4;screening_d;}\n\t\t\t{rank=same;screening_5;screening_e;}\n\t\t\t}\n\t\t\t\n\t\t\tsubgraph cluster_articles{\n\t\t\tlabel=\"\";style=filled;color=whitesmoke;\n\t\t\tnode[label=\"Studies included in synthesis \n (n = 40)\", shape=box, width=3]articles_A\n\t\t\n\t\t\tscreening_5 -> articles_A[label=\"Included articles\";fontsize=18]\n\t\t\t}\n\t\t\t\n\t\t\t}\n\t\t\t","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
```


### Data Extraction and classification

Considering the questions initially posed, we looked for the following information (if available) for each article:  

* plant taxa studied (if available), to estimate taxonomic scope of studies
* geographic location (latitude and longitude) to estimate geographical distribution of studies. If it is not available in study, we estimate the approx location using Google Maps and Google Earth. We also recorded the Indian state in which study was conducted.
* year of the study to estimate temporal distribution of studies
* Domain and subdomain of plant ecology for each the study. Adopting a single unique classification system for ecological studies is difficult as study areas often overlap. However, we followed the following broad classification system for the present study.

| Ecology Domain        | Included sub-domains                                  |
|:----------------------|:------------------------------------------------------|
| Organismal Ecology    | Population genetics, natural selection, behaviour     |
| Physiological Ecology | Adaptations to abiotic factors like temperature, light|
| Population Ecology    | Population growth, demography, age structure          |
| Species Interactions  | Competition, facilitation, parasitism, symbiosis      |
| Community Ecology     | Species diversity, succession, biogeography           |
| Ecosystem Ecology     | Food web, biomass production, nutrient cycling, soil  |
| Palaeoecology	      | Fossil records, palaeo-vegetation                     |
| Landscape Ecology     | Land use and land cover, ecological modelling, spatial and global Ecology|
| Applied Ecology	      | Conservation, management and restoration ecology      |

Table: (\#tab:tab4) Classification scheme

Next, we manually extracted data from each of the 40 articles and assigned an ecological domain and subdomain according the above classification system (Table \@ref(tab:tab4)).


```r
## read the screened fulltext and filter the selected articles
included_articles <- read.csv("./data/siwalik-ecology/screened_fulltext.csv") %>%
	filter(screened_fulltext == "selected")
## write the selected articles for data extraction
#write.csv("./data/siwalik-ecology/extracted_data.csv")

## read the extracted data
extracted_data <- read.csv("./data/siwalik-ecology/extracted_data.csv")
```

## Results

### Geographical distribution of the studies


```r
## read the boundary of India
ind0 <- st_read("./data/siwalik-ecology/ind_adm0.gpkg")
## extract countries for Asia
asia <- rnaturalearth::ne_countries(scale = "medium", type = "countries",
						 continent = "Asia", returnclass = "sf")
## A bounding box for Indian subcontinent
indsub.bbox <- st_bbox(obj = c(xmin = 67, xmax = 98, ymin = 5, ymax = 38),
                    crs = st_crs(4326)) %>% st_as_sfc()
## clip the Indian subcontinent
indsub.clipped <- st_intersection(asia, indsub.bbox)
## bounding box for area of ineterest
sw_box <- st_bbox(obj = c(xmin = 73.5, xmax = 80.4, ymin = 28.4, ymax = 34.2),
                    crs = st_crs(4326)) %>% st_as_sfc()
## prepare inset map
inset_map <- tm_shape(indsub.clipped, bbox = ind0) + tm_fill(col = "grey95") + 
	tm_borders(col = "grey85") +
      tm_shape(ind0) + tm_fill(col = "grey92") + 
	tm_borders(col = "grey80") +
      tm_shape(sw_box) + tm_borders(col = "red", lwd = 1) +
      tm_layout(bg.color = "#9bbff4", frame = "grey85")

## read the required data for the main map
# shaded relief for the area
#indsr <- raster("D:/spatial-data/Themes/SR_LR/SR_LR/SR_LR.tif") %>% 
	#crop(extent(73.5, 80.4, 28.4, 34.2))
#writeRaster(indsr, "./data/siwalik-ecology/shaded-relief.tif")
indsr <- raster("./data/siwalik-ecology/shaded-relief.tif")
# elevation data for area
#indem <- raster("D:/spatial-data/dem/india-dem/gt30e060n40.tif") %>%
	#crop(extent(73.5, 80.4, 28.4, 34.2))
#writeRaster(indem, "./data/siwalik-ecology/dem.tif")
indem <- raster("./data/siwalik-ecology/dem.tif")
# India mask to highlight the region
ind_mask <- st_difference(sw_box, ind0)
# boundary of siwalik region
sw <- st_read("./data/siwalik-ecology/siwalik.shp")
# study points
ex_data <- read.csv("./data/siwalik-ecology/extracted_data.csv")
study_points <- ex_data %>% filter(!is.na(lat)) %>% 
	st_as_sf(coords = c("lon", "lat"), crs = 4326)
## prepare main map
main_map <- tm_shape(indsr, bbox = sw_box) + tm_raster(palette = "-Greys", 
									 legend.show = F) +
	tm_graticules(col = "grey80") + # graticule
	tm_shape(indem) + tm_raster(alpha = 0.6, palette = "Greys", style = "cont", 
					    title = "Elevation (m)") + 
	tm_shape(ind0) + tm_borders(lwd = 2.5, col = "white") +
	tm_shape(ind_mask) + tm_fill(col = "white", alpha = 0.3) +
	tm_shape(sw) + tm_fill(col = "yellow", alpha = 0.3) + tm_borders() +
	tm_shape(study_points) + tm_symbols(col = "red", border.col = "white", 
							alpha = 0.6) +
	tm_compass(position = c(0.35, 0.015)) + # North Arrow
      tm_scale_bar(position = c(0.5, 0.015), text.size = 0.75) + # scale
      tm_add_legend(type = "fill", labels = "Siwaliks", col = "yellow", 
      		  alpha = 0.3) + 
      tm_add_legend(type = "line", labels = "International Boundary", 
      		  col = "white", lwd = 2.5) + # road legend
      tm_add_legend(type = "symbol", labels = "Study Sites", col = "red", 
      		  border.col = "white",
      		  alpha = 0.6) +
      tm_layout(legend.position = c(0.0035, 0.01),
                legend.bg.color = "grey90", legend.bg.alpha = 0.5,
                legend.text.size = 0.75, legend.frame = "grey85")
## aspect ratios for inset map
in_bb <- st_bbox(ind0)
aspin <- (in_bb$ymax - in_bb$ymin)/(in_bb$xmax - in_bb$xmin)
## aspect ratios for main map
mn_bb <- st_bbox(indsr)
aspmain <- (mn_bb$ymax - mn_bb$ymin)/(mn_bb$xmax - mn_bb$xmin)
## create a viewport for inset map
vp <- grid::viewport(x = 0.92, y = 0.98, width = grid::unit(2.5, "inches"), 
               height = grid::unit(2.5*aspin, "inches"), 
		   just = c("right", "top"))
## save the map
tmap_save(main_map, filename = "./data/siwalik-ecology/map.png", insets_tm = inset_map, 
          insets_vp = vp, height = aspmain*7, width = 7, units = "in", dpi = 600)
```


```r
## include in the document
knitr::include_graphics("./data/siwalik-ecology/map.png")
```

<img src="./data/siwalik-ecology/map.png" width="80%" style="display: block; margin: auto;" />



```r
ex_data <- read.csv("./data/siwalik-ecology/extracted_data.csv")
geo_dat <- table(ex_data$location) %>% as.data.frame() %>% filter(Var1 != "All")

ggplot(data = geo_dat, aes(x = Freq, y = reorder(Var1, -Freq))) + 
	geom_bar(stat = "identity", width = 0.65, fill = "steelblue") +
	geom_text(aes(label = Freq), hjust = 1.5, color = "white", size = 5) +
	labs(x = "Total Articles", y = "") +
	theme_minimal() +
	theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12))
```

<img src="02-siwalik-ecology_files/figure-html/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" />

### Temporal distribution of the evidence


```r
ex_data <- read.csv("./data/siwalik-ecology/extracted_data.csv")
temp_dat <- table(ex_data$year) %>% as.data.frame()
temp_dat$year <- temp_dat$Var1 %>% as.character() %>% as.numeric()

ggplot(data = temp_dat, aes(x = year, y = Freq)) + 
	geom_area(fill = "grey90", alpha = 0.5) +
	geom_line(color = "grey80", lwd = 1.1) +
	geom_point(size = 5, shape = 21, fill = "skyblue", col = "blue") +
	labs(x = "Year", y = "Articles / Year") +
	ylim(0, 8) + 
	theme_classic() +
	theme(axis.title = element_text(size = 14), 
		axis.text = element_text(size = 12),
		axis.line = element_line(size = unit(1, "cm")),
		axis.ticks.length = unit(1.5, "mm"),
		panel.grid.major.y = element_line(color = "grey80")
		)
```

<img src="02-siwalik-ecology_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" />

### Domains of ecology


```r
ex_data <- read.csv("./data/siwalik-ecology/extracted_data.csv")
temp_dat <- table(ex_data$domain) %>% as.data.frame()
#temp_dat$year <- temp_dat$Var1 %>% as.character() %>% as.numeric()

ggplot(data = temp_dat, aes(x = Freq, y = reorder(Var1, -Freq))) + 
	geom_bar(stat = "identity", fill = "steelblue", width = 0.8) +
	geom_text(aes(label = Freq), hjust = 1.5, color = "white", size = 5) +
	labs(x = "Total Articles", y = "") +
	theme_minimal() +
	theme(axis.title = element_text(size = 14), axis.text = element_text(size = 12))
```

<img src="02-siwalik-ecology_files/figure-html/unnamed-chunk-12-1.png" width="80%" style="display: block; margin: auto;" />

### Taxonomic groups of plants

Among the various taxonomic groups of plants Angiosperms 

### Top journal sources


```r
ex_data <- read.csv("./data/siwalik-ecology/extracted_data.csv")
ex_data$journal %>% table() %>% as.data.frame() %>% 
	filter(Freq > 1) %>% arrange(desc(Freq)) %>% 
	kable(caption = "Top journal sources", col.names = c("Sources", "Articles"))
```



Table: (\#tab:unnamed-chunk-13)Top journal sources

|Sources                                           | Articles|
|:-------------------------------------------------|--------:|
|INTERNATIONAL JOURNAL OF REMOTE SENSING           |        4|
|Forest Ecology and Management                     |        3|
|Tropical Ecology                                  |        3|
|Environmental Monitoring and Assessment           |        2|
|FLORA                                             |        2|
|Indian Journal of Ecology                         |        2|
|JOURNAL OF THE INDIAN SOCIETY OF REMOTE SENSING   |        2|
|Palaeogeography, Palaeoclimatology, Palaeoecology |        2|
|Proceedings: Plant Sciences                       |        2|

### Knowledge gaps

